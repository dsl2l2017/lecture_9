{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "Trains a memory network on the bAbI dataset.\n",
    "\n",
    "References:\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n",
    "\n",
    "- Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895\n",
    "\n",
    "Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.\n",
    "Time per epoch: 3s on CPU (core i7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "524288/600901 [=========================>....] - ETA: 0scorpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 674s - loss: 2.2437   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"relation\n",
      "(grundstellung) to all things.\n",
      "\"\n",
      "relation\n",
      "(grundstellung) to all things.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=lostincessions and the wisters and and the ways and and and the sore and and which and the and and in are the supporenters and in the surion of the reasion of the stirale the surilitions and and which and and the supporentens of the reared the proporenter to the stireding and which and the wisters and the sore and the sore the streat of a the man to the supporitions and and in the reara\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"relation\n",
      "(grundstellung) to all things.\n",
      "\"\n",
      "relation\n",
      "(grundstellung) to all things.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"relation\n",
      "(grundstellung) to all things.\n",
      "\"\n",
      "relation\n",
      "(grundstellung) to all things.\n",
      "ha ond\n",
      "all this, by low\n",
      "then. a\n",
      "dangiforerral, that sufforind with whucher thon inkentests adonsy boul althiny a\n",
      "candernts in is canalmaons and she, that\n",
      "indiseraplie.\" worlss which\n",
      "there heaited that was apsicnsere, hand and attieaticise--have, painots to\n",
      "desposere,\n",
      "and\n",
      "toe les, as stivelysore--whonarto ats conseoce, thouse, with, mitabligate, perroration and nedions, and becill to hads, the must\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"relation\n",
      "(grundstellung) to all things.\n",
      "\"\n",
      "relation\n",
      "(grundstellung) to all things.\n",
      "\n",
      "\n",
      "\n",
      "spephieale to\n",
      "poudciensentorsing,\n",
      "oraremen.\n",
      " is who eiriodopincitiens, and is avowled, canaysery-wind, a this devilie, why\n",
      "hepully\n",
      "ss\n",
      "asinco to be wisless howerterse morel\n",
      "can we wernouge, formcierld, and as in uf\n",
      "laty, las, dewundiniop, in favt \"but is some with in ausds-mey benahsleetial sornciorarable happervent fore\n",
      "on fower and has alsorston-avalledg in this, ather alsorencessmo, seeledion\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 549s - loss: 1.7541   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"physiology with a clear conscience, one \"\n",
      "physiology with a clear conscience, one and speals and the same and the same of the is the same the same to the same to the same of the same and the same of the solvers of the same the oritions of the sore and the something the same of the same and the prosent of the interpreters and the same of the any and the arrity and the sore and the as the same of the same of the good of the same of the instinctical that it is the same of the same\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"physiology with a clear conscience, one \"\n",
      "physiology with a clear conscience, one of a than the was the concertion, and spead consure with the formed and actions as an the the moral the dankers, and seemence, the the the self-surfections the same and in the way in the atternally there the will and self-sentions means and exoral probally feeling the sade with the\n",
      "self and and love his not men that the arritions as the happine so the actions and and the sortic and for enclase of \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"physiology with a clear conscience, one \"\n",
      "physiology with a clear conscience, one sadietal wast of everyacticable, priseroprign, whener\n",
      "sorames as astresticus, saet,, sublist and truetion tante many being and reasose, sureinamed as a \"wellle.\n",
      "for prose as is thinks that as sacreded. and wish with the orign of there cermance selvelly\n",
      "life applast blalence,\"ture, and tame, can lain of the good of the intereration, not it prowen be his strengthing, too rallob: true be theys\n",
      "meanf \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"physiology with a clear conscience, one \"\n",
      "physiology with a clear conscience, one gaidsing fature. a lifually in benoloking sackens,\n",
      "we has. with unsiet severeds, the thinch, torausitive occission\n",
      "varity is hearting fot, and is does smissaming bast proolarure. for abward soully namity, lea adproadse, his beilime,\n",
      "thinked, there part,\n",
      "of quilulitys,\n",
      "had samally itself-man saysia,\", the knows thee suches tealy to\n",
      "faction of a tardain, and nemally anyt leal, (forly with, than as\n",
      "w\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 278s - loss: 1.6409   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"be mixed with my evils (illness, lonelin\"\n",
      "be mixed with my evils (illness, loneling the some of a the spirit of a can be something to a some of the some and sortion of the problement and and a seared and a sorte in the experses and the for a problement to some and some and be the something to the experient of the some of a some of the experience and of the experient of the experient of the self-something the expression of a things and so the experiently the experient and a deli\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"be mixed with my evils (illness, lonelin\"\n",
      "be mixed with my evils (illness, loneliness, and german for and the former to so knows all the intersounts, and in can for in the resolution, which the are every to with in who for in reseration, and with one consideration of and shill with and sortions and a conception and strong and his being one consideration to so the say and sconds and deceptions for the probable be more the seared in the expression of a man of every saint a consip\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"be mixed with my evils (illness, lonelin\"\n",
      "be mixed with my evils (illness, loneliness\n",
      "remoren sympathung wurts, just is with manifesty, graptic on enigious, a had; he hancely steppnous, you far haf acking and ary prosomotions and why plibation or one\n",
      "fash knew his hosk and can inrer one dow lack of god the know for of other\" a pranking dounch to\n",
      "ismes every beary readical esspanificawitias world i casention\n",
      "and cony of the\n",
      "exaypical the formshor wistable asiung and ractive lust\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"be mixed with my evils (illness, lonelin\"\n",
      "be mixed with my evils (illness, lonelined: \"the tide-subjectation phoid van thing\" to maevold yet--realled\n",
      "something\n",
      "no\n",
      "splaeetious provertical acpoya-nepe, only \"longs of bees \"ebsting wat canviple need clivisloked att gsise\n",
      "\"achy uponutialty\n",
      "of dowercate.         t bliebing and strangeavowhistizatialisation,\n",
      "lidy, robling--lat man, socaas, evorourty! why appice, midifered word\" motentual \"too\n",
      "formernous the\n",
      "ors oby\n",
      "for and doesi, dim\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 233s - loss: 1.5874   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"her all mechanical action, inasmuch as a\"\n",
      "her all mechanical action, inasmuch as a presumation of the destible and subject of the subject and the subject of the subject of the present and and the subject and and the present to the present and a present of the present and and a strugglation of the subject and the subject of the subject of the subject and all the present and subject of the present of the subject of the present and the present and a play with the contrant in the s\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"her all mechanical action, inasmuch as a\"\n",
      "her all mechanical action, inasmuch as a precisely as it is art and and which even to would may is the world, and and life the thing in his will his sympathy also the great and spirit and specially the motive and as in so repreditions and like the best, and supsich may be intend and truth a train, the certain and init of the contrant in the genera"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l period, and and couraded in the strange of the constant to the new strain ter, is the way\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"her all mechanical action, inasmuch as a\"\n",
      "her all mechanical action, inasmuch as a rightinal offerthen in a strengiasive, is theirs, in any lifice at med to very yecition ancell\n",
      "in what is surcre\n",
      "nok\n",
      "and any thinks. it is a spiriity\n",
      "my been nothing moralared, is the which, emphomishs, and really the privisely inflict to\n",
      "fact reward to mistnes,\n",
      "whole is no belief good; now regutatere ill for pling la with\n",
      "\"amming\n",
      "the uncemmitates with has founding besperiding\n",
      "pussed.--wi gladict\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"her all mechanical action, inasmuch as a\"\n",
      "her all mechanical action, inasmuch as ascenolae\n",
      "finties, by playe\n",
      "loveds klet and philosophes\n",
      "having can bling of\n",
      "whole\n",
      "cas as on may dramestly: e\n",
      "brenoldo, hind fried\n",
      "yegerait all rsed.\n",
      "s appard, no every bad, ow to\n",
      "innorenal and but garm timeiative in orrual polig itsive. in earied of what sudrictods for things--pondurable certainf i dury\n",
      "  : and a deed what to,s precary angleist. how\n",
      "a right morelyer\n",
      "nowarach to know\n",
      "disindiveding o\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 233s - loss: 1.5555   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" a quite natural and due\n",
      "proceeding that\"\n",
      " a quite natural and due\n",
      "proceeding that is always the fact the wanted and always and the seems of the so the seems of the seems of the present of the world of the them of all the seems of the one the world of the soul. the world of the so the see the soul. the conscience and the world of the strange the seems and the pround of the sense of all the present of the self-self-self-sense has all the soul. the world of the sense of the proba\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" a quite natural and due\n",
      "proceeding that\"\n",
      " a quite natural and due\n",
      "proceeding that the self-self-servent of the constitution of the most decepthing nothing on essented of the thing and was that that is alove in the super to the seems to the wery strange, and of which in the end of conception, to the them itself to be the probable the most history of the orter that the wandeted and longer and that one that is\n",
      "conscience of the subjection of life, may ones manner and in and the g\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" a quite natural and due\n",
      "proceeding that\"\n",
      " a quite natural and due\n",
      "proceeding that be own mir,lead, the\n",
      "sightness. and one seatoment is moral, us gloodest artimned of would mlivions musicience on always has earandy had then\n",
      "whole-dreast\n",
      "anothers. howevereclnon has woolged\n",
      "of his kind\n",
      "of immedient to sense by a wruth re of michoriance is do famtifie say spley, or asteriable manifrepionolly and\n",
      "bettertom some worldnce it it boundnated,--an syngly, howeverever before us houds desp\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" a quite natural and due\n",
      "proceeding that\"\n",
      " a quite natural and due\n",
      "proceeding thatsit ho thye forder, all\n",
      "whildne of value, that labuling nation,\n",
      "his believiden and caseouster\n",
      "foreek, quitely, therewhither.--that motive, these\n",
      "retaitable a view of bective, is couldnamely\n",
      "hands--to guate. the meste much contisueniaty stronger-muss essence, qurth\n",
      "world, not attance\n",
      "what a\n",
      "tlaed, on mord to life, judgment people it, certain. nong fat, and taste canniced tale\n",
      "of the \"pacher be\n",
      "the \n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 225s - loss: 1.7753   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"kes you headstrong against\n",
      "objections an\"\n",
      "kes you headstrong against\n",
      "objections and soul of the such the experience and the seem of the such the sense. the sense of the such a present of a man of the something and to the sures and and and and the works and such a prevale the such a present of the present of the religion of the problem of the present of the such a present of the something and such a present to the such a present of the consideration of the present to the soul an\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"kes you headstrong against\n",
      "objections an\"\n",
      "kes you headstrong against\n",
      "objections and the higher of the strong in his with they are in so the free propen of the higher of the prowitible present to contranices of all the consideress in a man of the such as a \"such as and sufferings and most consideration of the love and sense, and detire the word and conscience, and belong to a king as a present of the considerated to everything in the forman to every\n",
      "reason for out of the persons\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"kes you headstrong against\n",
      "objections an\"\n",
      "kes you headstrong against\n",
      "objections and long to reew coneding \"popiticared it for the most prosciprises--when we were, what is we imperfous to\n",
      "who loous of men of very superion of the recece \"lipsicile, in eurp to our consisted as it power, ray pharilaked. perhaps are the breadude day \"to\n",
      "christianity to how and mountly, in every\n",
      "ascrud courseofu we prys,lights who was the portipecicied night of \"smounted,\n",
      "and does ereles much heavour\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"kes you headstrong against\n",
      "objections an\"\n",
      "kes you headstrong against\n",
      "objections and contrestal\n",
      "exactnets)\n",
      "in they do everyto-daring for\n",
      "errors\n",
      "savext, aplo--nouds for tyesed many--forms.\n",
      "\n",
      "1 natestell inmencics or fas fagually nopames, but a noble haids\n",
      "petsulving thaday\" \"fachy that thateino. one mare the parting that and is of mertion, man of christianione. every\n",
      "clans world and contert\" one little naturiness.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "cached. on\n",
      "the love a partance, him we does in their\n",
      "historder\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 233s - loss: 2.0384   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n-authoritative, and non-self-sufficient\"\n",
      "n-authoritative, and non-self-sufficient of the sudefice of the position of the considerable the sudes of the perhaps and the considerable and something of the position of the self-sense, and the something of the same things of the prosonal and in the really and considerable and the most to the prosoacially of the perhaps the prosoors and something of the then the perhaps and the most of the self-so the perhaps and the prosountary of th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n-authoritative, and non-self-sufficient\"\n",
      "n-authoritative, and non-self-sufficient to the\n",
      "portumable of the consequences of an everything to the consciously to something experient and delichaon and his their consequences and stacked and order to and the most religion of the decocion of the that there is all the prooffoste, and order of the considerance and the way of the advance of rightly discover of the discover, and are also they the masteric in order to precisely to the som\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n-authoritative, and non-self-sufficient\"\n",
      "n-authoritative, and non-self-sufficient. what is a late\n",
      "socual higher and lentle.\n",
      "\n",
      "\n",
      "140d authounfing, instance, is the\n",
      "thing and disclonly consciously and\n",
      "the funder forthing aturedoaxions of different, all of can exofly from which, innowed iononity, them conception, how fear, whateed. too\n",
      "such a woom. than in the significantslictommence and with longing--therout for sure\n",
      "than can us theow so resrepses, plean of\n",
      "knowledge, howring and \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"n-authoritative, and non-self-sufficient\"\n",
      "n-authoritative, and non-self-sufficiently so rokd who tain, and merable a dompy that in the\n",
      "something and higrem, init of\n",
      "the spirituality nothausis, to also areacuncy of believes richons. but looks and also has higher constitiem, everyty\n",
      "sougowh, in this sethner prodo--say, ponisudly these belief, individualsion with pleaces contrithorder, to mysel demicts and yepsed,\n",
      "this species ated no mencise, afford the gopoun only re-nisaldes, i\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 221s - loss: 4.9621   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ncipal moral judgments, europe has becom\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncipal moral judgments, europe has become aieseared the aies aieioesion ooioeationsiesineas aiestion oioesiaily stiling of aimality aies a stranofice and ane and a ioldered aim of the stioed the personationaieaing aim ofieit to a sioeaieary of the and andeart aies and the areadeared aies and sueger toal and aies aon a iomineal of theioious and and aies the senealed the areineding and the aieseaingedinged aies and and and theaing the sue\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ncipal moral judgments, europe has becom\"\n",
      "ncipal moral judgments, europe has become ioeveaned analeeitsoeaieiseationaieatian\n",
      "oimer of relieain oimsinged and same dactioeed ioeat,inificeal sieg the maies. heareed ane and aneear theeiseaisedied wiedioes, aid, and oodedeiailyinatedion aiewilieitain, the woritionians ofing andainiteait,odedeainineas ofealed the live the adeeationity anared aim andiois,oratiois ioive. to amongain woed, aiditedityaliedieitive thearkines anelameitedit\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ncipal moral judgments, europe has becom\"\n",
      "ncipal moral judgments, europe has become iai aimaboreoweeed aioeeinieatioeaienoicedigneevedieseaiintticeach andity.nnerarionmeainifluseseatureeayimentsory noee\n",
      "intoeatorityinedalaieeal oears. aim oeature,o ofees asear maiear-aimal wiee aegeaieationearingesanoseimes aocleooeat nois away berientiate aoeious\n",
      "aige--an actait,ileioiaaileas and aidious\n",
      "aimour the ooioueilimairosoody mioualitreionoediaitaledeealeaneal coneoee, saitaeal defana\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ncipal moral judgments, europe has becom\"\n",
      "ncipal moral judgments, europe has become aieriedate oo\n",
      "eeataieaaie.ian, aoieition aiieits engpeiince empeesition, aoestic meeiom wouad fimeaieaieateioneatered aiiaeeaiering, yeioie of\n",
      "oureainifeeaiss,ipraoyeioesoulooeriessmin;edss aieivatioeaismaiede feeblaaned intoot venaion oo\n",
      "noelalialismaiviageationious\n",
      "the\n",
      "instan orem evenolesing sect realeas  asing suaveence and at relieioioe conesstyping,   ailious spioieetaiidesomantoyinaeedian\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 216s - loss: 8.7971   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rom which we go,\" the\n",
      "sensation of the c\"\n",
      "rom which we go,\" the\n",
      "sensation of the ceeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rom which we go,\" the\n",
      "sensation of the c\"\n",
      "rom which we go,\" the\n",
      "sensation of the ceeeaieeoeeioieeeeeeeeeeeeeeeeeeeeeeeioieioioeeeeaieeeeeeeeeeieeeeeeieeieeeeeeeeeeeeeeeeeeeeeeaieeeieeiooeeaieeioeeoeeeaieaieeeieeeeeeeeeeeaeeeeeeieooeeeeeeoeeeeeieaeeieiooeeaieeeieeaieeaeioeeeeeeioieeieeeeeeeeeaieioieeeeeeiooeeeeeeieieioeeeeeeeeeeeeeeioeeeeeeioeeeeeeoeeeeeeeeaieeeeeeeeeeeeeeeeeeiooeeaieaieeeeeeieeieeeeeeeeeioeeeeeieeeeeeeieeioeeeeieeeeeeeeeeeeaieiooeeeeeieeoeeeieeeioeeaieioieeeeee\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rom which we go,\" the\n",
      "sensation of the c\"\n",
      "rom which we go,\" the\n",
      "sensation of the coeeeaeeeioeaeioeeeeeoieioieeeioooeeaeeeiooieoeeeeioeeeeeeioieaieoeeaieieioieeieieeeioeeeooeeeieoeeeoeeieaeooeeieooeeeeeeaieeoeieeeeeieoaieeeeeaeiooeooeeieaeaieeieioieeeoeeoeioeeieeeeeaieeaeioieioieaioeaeieeeaieieeeeaieeeeeeeeeeieioeeieoeeeeeeieeeaoeeeeioeeeeeeoeeioieioieeeioeaoieaeioieaieieaeiaieioeeeeaeeeeeiooeeioeeeieaioieaeaeioieeeaeaieeeaeeeeaieeeeeeeeoioeoooeeoeeeiioeeeeieeoeieaieeeeieaieeiea\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rom which we go,\" the\n",
      "sensation of the c\"\n",
      "rom which we go,\" the\n",
      "sensation of the caieoooeeeeeeoieeeoioeeaieeeeeeeaieoeeeoeeeaiooeeaeieioeeaieeeeeeiieieeioeeeeeaieoeioeeoeeeeieaeaoeeeaioeeeeaieaieeaieaieaeioeiooooieiooeeeieeieoeoeeeooieaioeeeeeaeoeeaaeioieeioaieeeeeaeioeeeieeaieeeiieieaeaieeieeieoeeiooeoiooieieeeeioeaieeeieaeioeeaieieiooieeiaieaeeeeeoeaieeeeeeiieioeeeieeeioeeeeieaieaieiooieioieeeoeeeeiaeioeaeeoeioeeeoeaoieeeioeieieeoeeeeeeieeoeeaieieeeeeeaeeaieaeaieeeaiaieaeioio\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 231s - loss: 10.0991   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ar, the more ordinary\n",
      "people, have alway\"\n",
      "ar, the more ordinary\n",
      "people, have alwayeionaienaieedioiouaieioioeseasoioioeseaieiomaietoooeaieioeaieeaieioioeaieioeaieeaieeaieioioeaieioioeaieioioeaieeaieeaieeaieeaieioioioioeaieioioeaieioioeaieioioeaieeaieeaieioioeaieioioeaieioioeaieioeaieioioeaieioeaieeaieioioeaieioioeaieioioeaieioeaieioioeaieioeaieeaieioioeaieioioioioioeaieioioeaieeaieioeaieioioioioeaieeaieioioeaieioioeaieioioeaieioioeaieioioeaieeaieioioeaieioioioioioeaieioioioioeai\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ar, the more ordinary\n",
      "people, have alway\"\n",
      "ar, the more ordinary\n",
      "people, have alwayooonoioliaiouaiee,oaieeaie aimeaieionoioiousioileaieioeaieioeaieiomeaiaieeal oooeaieioesioioeaieeaieeaieioeioioeaietooeaieeaieaieaieaieioeaieioeaieeaieeaieaioioioioeeaieioeaieioeaieeaieioeaieeaieeaieaioeaieioioioioioeaieeaieeaieeaieioioeeaieeaieioioeaieioioeioioeaieioeaieeaieioeaieioeaieioeaieioioeaieioioeaieioeaieioeaieeaieioeaioioioeaieioeaieioeaieaiaieeaieeaieeaieeaieeaieioioeieioeaieioioeaieea\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ar, the more ordinary\n",
      "people, have alway\"\n",
      "ar, the more ordinary\n",
      "people, have alwayooeseaileaieseaiesooaieeaiteegaieeaieieaoioaieinaieioeaieioeaieeaieeeaoeaiaieioeaieaiainiaieioeeeioioioeaiaieieeaieioioioioioeareeaieaieioiaieaieiaioeeaioioeaiaieeaieeiiaiaieaooooooooioeieeioaieioioeoioioaieioeaieeaieaieeioaieioeeaieioioeaieeaieeaieioeeaieioioeieeaieioeaieaiaieaoooeaaiaieioioioaieeaieeiaiaieeaieioaieeeioioeaieeieaioaaieaieaioaoieaioiaioaieiaioooeeeaieioioioioaioioiaieeaieeoeaieeio\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ar, the more ordinary\n",
      "people, have alway\"\n",
      "ar, the more ordinary\n",
      "people, have alwayiaesiainieiouaieieaieioioieaineaieioseaieioeaie.aieeieaieaaieiaioioionaieioioaieeaieeainooioeoeaiaieioeaieioeseooiaieaioioioioeseeaioioioioioeeeaioeaieieeaieeeiaieaioeaieioioaiaioaieioeaieeeaieioeaieaieeaieeaieeiooaieeeeeaiaioioaoeaiaieioioiaieaiaeioioioioeaieieeaieeoeaieeaieaieaiaieieeaioaaieeoaioioioaieioeeaiooeaoeaioeieaiaioiaioeeoooioooeaioooeaieeeiaieaiooaiaieioeaieaioioiaioeaieaiaieaioioeiea\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 235s - loss: 9.8775   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nvironment, in ourselves, not in the mur\"\n",
      "nvironment, in ourselves, not in the mureaieitioioioioioioioneaieioioioioioioioioioioioeaeieaieioioioioioioioeaeieaieaieioioioioioioioioioioioioioioioioioioioioioeeaieioioioioioioioioioioeaeieaieioioioioioioioioioooooieaieioioioioioeaieeaieioioioioioioioioioioioioioioioioioioioioioeeaieaieioioioioioioioioioioioioioioioioeaeieaieioioioioioioioioioioeeeaieeaieeaieioioioioioioeaieioioioioioioeeeaieioioioioioioeeieaieioioioioioioioioioioioi\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nvironment, in ourselves, not in the mur\"\n",
      "nvironment, in ourselves, not in the mureeaieneieioioioioeaineaieaieaieioaieaieeaeieioeaieaieioeeaieioioioooooioooioioioioeeeaieioiaieeeioioioioioeaeiooooieaieioioeaeieeaieaieaieioeaeieaieioioioieaieaieeaieioioeaeieioioooooooooeaeieaieioioeaeieaieeaieaieioioeaeieaieeaieeaieioioioioioioioioieaieioioioioioiooooeaieaieeeaieioioioioeaieioioioioeeaieeaieeeeaieioaieioioioioioeaeieeeaieioeeaieaieioioioioioeieeaieioioioeeieioioioeeaieaooooeaeie\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nvironment, in ourselves, not in the mur\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvironment, in ourselves, not in the mureaieinaieioioioioeievioioioeeaieaieaieeieaieioeeeeieeeaieaieioioioeeieaieeeeeaieeeaieeaieieeieaieioioaieioioeieaieeeioiaieaieeeieieeaieaieaieeaieioieioioioioioeeaieieaieioiaieiaieaieeaieioeaieioioiaieioeeaieeaeieaieaieaieeeeeeaieeoieieieaieieaieeeieieieeaieeaieioaieeaieaieooioioioioeaieeaieieeaoioeeaeieeeioaieaieioioioeeaieeoioeeieaieioioeieaieaieaaieioeeooooeeaieaieeeeaieeeeeeeoooeaieaoioaieaieio\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nvironment, in ourselves, not in the mur\"\n",
      "nvironment, in ourselves, not in the mureeaie aieioioiieaieitaieioaieeiieeaieaieaieeeeaeieaieeeaieiaieaieeeieaieeeaieioieioaieioooeaeaieeaieieeaieeaeieaieaoieaieeaeieeaeoieieeieaieaieeeaieaoeeieioiaeieeieaieioaieioioieaieeaieeieooeeeeeeaieeaieiaieeaiieaieieaieioieioaieaieioieaieaieeaieooeaieeeeaeieaieaieioeeaieioioiooieieieaeieaaieaieeaieieeaioieaaieieieeeaoeoeeaieeeieeaeioeaieiaieaieaieeeaooooooooeaeieeeeaieeieaieeaieioaieioieeaieiaiei\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 225s - loss: 9.8746   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", these wrongly\n",
      "named \"free spirits\"--as\"\n",
      ", these wrongly\n",
      "named \"free spirits\"--as tooe inacress, aieainiaieity in the selfeines aieaines aim andee to the ioe to the in ioer aim oo now iomestering ineveare in ioer ooo in too in oriminies, aiealin theie which their such in tooen oooes anoeaie ioeesseaieity of theie iseieaing aieaie oooes ioe whice hieaiesesear, to aieaieieaie theire aieseaieiouineing in ioeeioeaieitioealitioeseieation of the shiein ioeer anainedineseieation in o\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", these wrongly\n",
      "named \"free spirits\"--as\"\n",
      ", these wrongly\n",
      "named \"free spirits\"--as seietice on accieaiese ooo anaining to thaie aiever aiwaieiesooeit is and\n",
      "oreeteaieitioeaiteaieieaieieyereringe aneioioioies, to feaieieeieeaieious peaco.ikeneiseacy of wieaieaieieaieaisingeans anaiee iom iom aieaieioeaieiesed ieaing asoieater has tooeaieseeeioealiation to inaieieeation aieieainieaseion and ender aieioioes of aieered eievery aiminessingioalieeation oaieieedioeaineseacesed and a s\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", these wrongly\n",
      "named \"free spirits\"--as\"\n",
      ", these wrongly\n",
      "named \"free spirits\"--as eieite\n",
      "itself--ioieabetoooy aivet cauas oeouseder or woreaieaieiesianiaie ioeaieiois erioealaieieaieioeainned ooo heaeaieiouse hoie eaieioious--thaieieim aieieeaie to ioealieiesaian, heaieieoensioieeesea,ive\n",
      "oooveioe\n",
      "age sooeioeainian iaieacaitaieiaieeisaiseeedooners the ex eeaient poioioeaie aidaieaietion ofenay aookeringadeoaieaipieaieibeey own ooosedeaieate ioueaieiveroioouieeieriouaie tikeiei\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \", these wrongly\n",
      "named \"free spirits\"--as\"\n",
      ", these wrongly\n",
      "named \"free spirits\"--as saie isichove raieaieiaieif\" of waeveigatiealipeeeemoloeieiaiiouac fooneeoeatioosaie,s ooeie.\n",
      "\n",
      "aiet-ameligediediieiigeaifioes\n",
      "oooeitioneieaaieeceieawesting oodingeeoaieaiy\n",
      "be-eeeaieieeieaieicy whioderieiooooes ofaiseeeeieaieieeat,oores, monaineaieac on ineaeieioiaiaieioeaieicied andiaieives us aoaeiverseeeay iooromeooviaeeaieieate aneaoeaieineiiboueeeitioe caioioeaieioopeueereaims ineiouaie asoxa\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 200s - loss: 5.8534   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"vain: again and again he\n",
      "experiences, pr\"\n",
      "vain: again and again he\n",
      "experiences, proper and been and the mayed andereaity andering aiealishedered the supeated and man tooun aimaieaienessioises anoent of the and the proed anain anaie theired the and beenedeeses to resticaineieiticeation anaie ieeaieationeess in to a suiety and andersear and a oener tooun ied and who wiee ioms and belieineates the straniesseseed ofolun seed andereaitioialies ie aieaiety and toee he aimationer ofoe\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"vain: again and again he\n",
      "experiences, pr\"\n",
      "vain: again and again he\n",
      "experiences, problem to the propomime inetted.e;ioed, is aighingine,oes ofirive along andeaes aimame that as aiveratteary ane foriseation oo ender a mayeainaise of a man aimation foelearates oes andient, and to necessuareiteaitiee aiest inevert be abouieateeenesein their part anotatioeal and anaieeres in ioeed oa\n",
      "instrias. and we for toaieal\n",
      "intoealies and a period toak a maint. it toweal iart of coars been the \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"vain: again and again he\n",
      "experiences, pr\"\n",
      "vain: again and again he\n",
      "experiences, privation. it is pusual\n",
      "oacediealapeaisary, it over paie iaiver a oeevoes aiwainy haie\n",
      "saince, eimy,\n",
      "and eaieteeared awards man, weaeh,ol thin, oereeieeiaiedeeained orreailied soen tackineanaitatioaite aink oes theiranion--whoee nich about and bundiatioeeess\n",
      "may aisees ioed as anyandimion\n",
      "ifeeeinifes, noieied.\n",
      "and in the appiemwiciallyineals eniieyity as poipet andare!\n",
      "aivatt,aikare mue\n",
      "and notyeuti\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"vain: again and again he\n",
      "experiences, pr\"\n",
      "vain: again and again he\n",
      "experiences, procrinity is and knows\n",
      "give oes eveaioueagion, healine-madeties, eaveeeyeie-tyeitatived eartee--coerlearde,oeee,oeacrois a haim aieeeousioes.aooeeroaieguinatioe, sometateaie and iegleneare\n",
      "faish and\n",
      "or artirieiane,\" tooeitedianion\n",
      "seas ofowisie is a deavaseenomeaily and ienert; is oe simeyme\n",
      "ofaies\"sandad him.\"ine, wioe ae\n",
      "fomen\"able--ease\n",
      "first certaie oedgincal ifepsyigedealaitaeseaseanwieiths of\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 220s - loss: 5.8762   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"stry, patient adaptableness to rank and \"\n",
      "stry, patient adaptableness to rank and the conscience of the sensible the standing and and the sensible the sener of the conscience of the suppe of the self--the self--the factor of the states and the sensibleal the suppe oot and the sensible and the sueded the some something and more and the suppeary of the sensible to the someter that the something and the saint and and something to the suppe of the something the self--whicosts of th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"stry, patient adaptableness to rank and \"\n",
      "stry, patient adaptableness to rank and depress of the stronored and the more worther to theose in the somethies the strive cannot the this on action the artific proble of the sening such a the truth--there is the very the servely of a case the divines, in the usists, the stast internal into the to\n",
      "the sament and soment of the procral some and something to end\n",
      "say to knowledge of the procration of the aboly instrarce the charaction of s\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"stry, patient adaptableness to rank and \"\n",
      "stry, patient adaptableness to rank and panden and untest frane for last that the kearming endurg\n",
      "to the upan. lever moraly sheness and debageeded statfatation so, or to geners of the\n",
      "from world, almost farcis martide wito tram seem nece of act to the muss art to ersarceuness than cannot of own criments and know aimal have accedsman all, right--ilne himcemus. his goeat the hone of\n",
      "the rogious instrously in the docopl ane appoie in the l\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"stry, patient adaptableness to rank and \"\n",
      "stry, patient adaptableness to rank and sempa is efyvef deceace.--y --, or asticapibevers.clif-turcicre sidrely nothive tanosted doe\n",
      "which, delogiae ertantesse of loweran-resoinch disslecce, are plediation. \"a ma knivedles deceivesk\"\"\"deavieger that so\n",
      "of the to sensible pary, in that loxks crascolitary satisly phoviacecibely shill, socringance inlupiseness te one--the\n",
      "pla, that which, in the dever\n",
      "exvant \n",
      "  eshiriste\n",
      "is everything moll\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 234s - loss: 2.4560   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"onality in the general constitution of m\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onality in the general constitution of more the come_itice the string and vain the_ the string an_ te_ the comes the someits ies the string of ties teem teem the survigitiäc, the s_ the_ the strianole_--the som varieient tho_ollion to the ents oed varient the_ ten_\" the seculeity and caster this iom the streind the stronger \"stigator the seeed virtues oes the éblom onotëity aiused the sur_ed and iä--a flection, what_ is te_ to the comes\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"onality in the general constitution of m\"\n",
      "onality in the general constitution of man and virtue_ is the liber us the\n",
      "trat woh its preising foe_ feornees fious qeeæ-about and fatæ. with the a selvion like teems for \"so comesed\n",
      "oent the feeline_ respicy and virtue agains_ede_ lange in orieses of his e_ëk all fromen but one woul ughe_ tay vaniäg, lange and ught ases_goowee, the an at_ to te_ presio_erronseindieice oo \"fully to tæventy, which the strugh_ virtue moral the surve_ed a\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"onality in the general constitution of m\"\n",
      "onality in the general constitution of morige he kin_iois\n",
      "the derinatiés as in progeéxeitly, in daniæger reeptliced goo the rind, whe febleryiers, to andentoët: iékings,\"ioisor the oryolyial putious ;\n",
      "and moe;ily\n",
      "bitan_ios.\n",
      "lange ore, a part was near floument, prassuainlying varain aulow that predice tumenty cirly untuly, oleigain \"sary, ohe gation callyinge, very\n",
      "polens such-treége_s--the lipmsee was_ to that as oppoieiidatioiëf sateoi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"onality in the general constitution of m\"\n",
      "onality in the general constitution of more? the chaëe if man. the knoeceourinallying veilityinofly, manoépatuon himselage sontu a--selil keet forp teup\n",
      "at neiliarls,\n",
      "the \"thein iour of\n",
      "fit\n",
      "bans, the veryeineied pitaovoe_s\n",
      "of sartiale, veilinerates by to agreatiëitroming\n",
      "nerdes. and a! yoeinity, whia pria\n",
      "worated orierance of countinedioes agaiäa,\n",
      "ooe_\" is a moil,\n",
      "beee moral\n",
      "ad marnes morefre ling at: ieepeat the äd. lave sive, viil e\n",
      "a\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 227s - loss: 9.0764   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" compulsion, indigence, obsequiousness, \"\n",
      " compulsion, indigence, obsequiousness, aieaieiyiaioniooaieieieieariieoeoreipeaioneareneainereaiafoheseeiooo ioiori xoieaiieeaieieiefeieiieioeooeeaillieari wanieareainotehineveitofieaiaieaheiearogeoe_ionaioeaiie ooeipieihieoeseeaireoveoieix itoieaioweneseve_ieakieieaioeriieie.oef tiovioaiooeililip aiomarieoiegekiviweaiseieieailixoiniced ieiee tieseioieaiieaesesereis isaixaiansueaiehesereregeeinaiaieie.eegneaoioieieieaiooieoisiyieieieato\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" compulsion, indigence, obsequiousness, \"\n",
      " compulsion, indigence, obsequiousness, eaeieieseaio aiioaieieieoeseieeiifei7oieieave aliooo oooeipe iiaiiym iadioieiesoeeooeooleaieieiereveryioaidehhei ofe oaieieiiieyioeaseseoalikeieasooeaiaieieiearatire iooeaeie,oiehiieieasioiegeseoe aieaieiesfioieatioemaiotesoon.aieaixieatalionesaaieireoeneooeieiixearse aed ioeie aioaiailieooieaiere aieeeo aieaiefeooai\"ieaitie; aieseipiaiaieieie\n",
      "itie;ieieeonanaiteaipyifici  eimaliyioiy.iferi pooe of\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" compulsion, indigence, obsequiousness, \"\n",
      " compulsion, indigence, obsequiousness, ieeaiierioiateeioeoeiiaieixiieieasienogiseieifoilaieieeheaience andivinien aieeosefieie. ieimaooaereoaile\n",
      "airwhoeeeoniaixienevenchiieieaieaeaioeoaieoaioooei xoptleaeieeiiegereeaioaipeaiooieo oaieoehieasiaioieieiaidiaiaianoeoeoaliaieaieiailie\n",
      "menepe;inef. asieaioieeaiveexiesieangaesaieonenooe iaesoei ixoood earsiflioieieae,oieaioeouiie eeoveiaaiaiaevooe oeearieieatieoooeeeaieiheioeiefieaeieaiaiooes\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" compulsion, indigence, obsequiousness, \"\n",
      " compulsion, indigence, obsequiousness, eaiaioiyaioowiaeiieiaieaio iaieeitieeianaiteneiainoianiieaeseliiaifmeraieeooeeanaioeoegooeeioyiooie4ereeeaeieoilioaiieieafaioeoeoeihy,oeieoiicooaeigietioieeseaioiaieioisieaiaio ieiiiaeoeseweigereareotavireaais oatieiptoeseoioitaiioeaieiaieiaieieeieieiakeieoiei\n",
      "iedioieoooeowadiaitiaieieboeeieiorii.aen ieaeoeoiaioieoraispoaideaeailieadyadoeopeieieieboueeeoooeioieniieiiareioeoeaiionesooeeioieieaaioo \n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 293s - loss: 7.8910   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"worst of all tastes, the taste for\n",
      "the u\"\n",
      "worst of all tastes, the taste for\n",
      "the ueed, wit and ionerver insiehie comeeeriantest the se oar ais the soee ioerexol the s aneer tiio the stirteoeistionesichiie. bevoerne ponco\" the ioer, coeal woin cere, inge the ief teir ofe ieigileiindioie the iomede ffr ange iner. beetoges to thexes in but the healy the iomeeees, indie;\"-he toar toreis  theat mos the beeliteneiencoeenteoligned oeo wher aistis preihale aigerr in in soaeoniir pren, \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"worst of all tastes, the taste for\n",
      "the u\"\n",
      "worst of all tastes, the taste for\n",
      "the ueed, beling aionare phe\"see,ait inaye ioly sue, phi\"eve eor ioseleocanal eare too ine he ioioe the paoe cooanseqieicityiingnoeeed ofioneot ioe iaiond minesecione iselfurderee\" is ooe pleis mritatie,e-thher ais hit aimeiion furd evinisher wioear ponesioittsiallim too thes inoninoge in wiserear ardiplem ceencolest ind ieeve perayieestin presioiii ais aind amme\n",
      "as suecheroant sat the cer inge e ais i\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"worst of all tastes, the taste for\n",
      "the u\"\n",
      "worst of all tastes, the taste for\n",
      "the ueie; cauinteceehe us -e eie.aspfosite aioliooioer ooe oan its sfioerinytiiliy the\n",
      "mooles iiireerrika ugoiiton hass roowisoaiioely aiondifeoaoeeo thar aar iaieineenssite srielt, aioie,it ionsee ullde koar ibialyos\n",
      " too sisad -hear e, eryoereairitinludinisieestele wiatichoon beelyind of ffe wh nal norer iniininaiched\n",
      "houe roeriehtiar as hions whund toriis.ioeee oa ad angoioersioit bieiry cinture efu\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"worst of all tastes, the taste for\n",
      "the u\"\n",
      "worst of all tastes, the taste for\n",
      "the uiet-teed\n",
      "ad\n",
      "tio ixuntioneaisiir ofiri\"io oite-se an, nooinoalmeye, w wase,\n",
      " ed oue-itiigalte koilniovernallareecoannt aioerve aaereem acomeene tingire aan toolre-ooe oan dligeeeuitt and oamed  e aeenledeeseachichied\n",
      "sant- soreiehploaileatusesteaoiaiueit ionercrt e-straneatrliiee\n",
      "isosoeveriohaleitiseaiaine irtiie raletin ereritimidere shuohimsfxe andiceoe\n",
      "nimus --sun und oamsaifins the ke oeao hals\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 223s - loss: 10.4608   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"\n",
      "pressure and hammer of which a conscien\"\n",
      "\n",
      "pressure and hammer of which a conscieneeeeeeeeeeeioieeeeeieeeaoeaieioeeeeieeeeeaeeeeeeeeeeaeeeeeeeeeeeieieaieaieaieaeeeaeaieaeeeeeieaieaeaieeeieeeeaieeeeeeieeeieeeeaeeeieeieeaieeeeieeeeeeeieaieieeeeeaeaieeeeeeeeeeeieaiaieaieeaieeeieeaieaieaieeeaieaieaeaioaeaieeaeeeaieeaeeieeeaieieeeaieeaieeeieaieaeeeieeeieeeeeeeeeeaieeeeeieeeieaieeeaieeeeeeeeeaeeeeeeeaieieaieeeieeeeeeeeeeieeeaieeeeeeeeeeeeeieeeaieeaieeeeeaieeaieeeeeieeeeeeeeaeaeaieeai\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "pressure and hammer of which a conscien\"\n",
      "\n",
      "pressure and hammer of which a conscieneaieeieeaeeiieeieieeeaeeaiaaeaaoeaeeieeaoeeaooeeieeeeeaieoiaeaeeieaieeieieaieeeaeeeiieaoieeeaeaaieaieiieeaeeeeeaeeiaoeioeeaeaieeeeaieaieeeeieeaeeeeeaeeeeeeaiaaieeaeeeaeaeaieoieeeaeeeeaeeeeeaeeaaeaiaeeeaeeaeieeiaieeieaoieeeaieeaieaeeaieeeaieeeaeeioeeaeeeeeaieeaieaeaeeieioaieaieaieaeioaieeeieaieeeieeoieeeeeiieiiaeeoaiieeeeaeaieeeeeieaieieeaieeaieeeaieooieaeeaeeaieeaeeeeaieieieaieeeeaieaeieeioeeaioea\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"\n",
      "pressure and hammer of which a conscien\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pressure and hammer of which a conscienoaiaeeaiaeiieeeiaaoeioieeeaeaieiooiaeiaeoiaieaiooioeieeieeaaieaaaaiieeieeaeaeeieeoeeoieioeeaioeeaaeeaieeeieaeeieaieaeooaiiaiieieeeeiaeaeaeeaeeieeieeiaeeeeeaaeeiaeeiaioieaeeiaeaoaeaoaeieeeaieaioieoaeieaaeaiiieaeieieaioiooeeeiieiaiaieeaaeaeiaeeeiioiieoieiieaoeeoaeeeooaeeeaaieaieaooeeaeeieeeoieieeiaiaeoeaoieieieeeeieeieeeeaaoiaiaeeaieeeiaiaaeiieaaieeeeieeeiaeaieeeeeieeeaaiaaeieiaeiooooeaaeeeieaiaeeie\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"\n",
      "pressure and hammer of which a conscien\"\n",
      "\n",
      "pressure and hammer of which a conscieniaieiooaaeeeeeeeeeiaiaeeeaoaiaieooiiaaeaaiaaeaeeieeeaeeaoaeiieeiaeaaiaieaeieaoaieioeeeaaoeeeeeoaiaiaeeaaeeaaieieieoeaoeeeeeeaeeoieeeiooioiaieaeieeaieeaeeieaeeioeaoeeeeiieaieeeeaoeeioaeaiiieaeieeaiooeaieiaeieoaiiiieaiaaoaiiaoeiiieaieoeeoiieeeeieaeeeoaioiaieooeeaaoeoeaaeieaieeooeieaeioeooaeeiaeaeeaieeeieeeiiaieoeoeiieieaioeeaeaeeaoeeaeaeieiaoeeaeeiooeiooeeaieaioieaioaieaaioeaieieeeieiiieiiaeaieaieai\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 243s - loss: 11.9022   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ave a cry of delight and for a moment\n",
      "be\"\n",
      "ave a cry of delight and for a moment\n",
      "beeeeeaeeeeeaeeeeeeeeeeeaeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeeeeeeeeeeeeeeeeeeeeeaeeeeeee\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ave a cry of delight and for a moment\n",
      "be\"\n",
      "ave a cry of delight and for a moment\n",
      "beeeooeeoeeaeeaeaeaeaeeeeeeeeeaeaeeeeeieaoeaeeeaeioeaeeoeaeeeeeaieeeaeeoeeeioeeieiaeeeeaioeeaeaeeeieeeeeeeeeeeaeeeeaeaoeeaeeeoeaeeeeaoeeeeaeeeeeaiooeaeeooieaieeeaeaeeeeeaeeeeeooieaeaeeeeaeeeeaeeeeaiooeaeeeeaeeeeooioeeaeaeeeeeoeeeioaeeeeeeeeeaeeoeaeaeioeaaeeaeeeeeeeooeaeeaeeeaieeaieaaeaeeaeeeeaeioeeeeeaioeeoaeoeeoeeaeieeeioeeeeeeeaeaiaeeeeeaeeeeaeaieioeaeeaeieeaeeeeaeooeeeeaioeaeeaeeeeeeeeeieeeeeeiea\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ave a cry of delight and for a moment\n",
      "be\"\n",
      "ave a cry of delight and for a moment\n",
      "beeooeeaaeaeooieeeaeieeaeeioeieeoeaeeeaeeaeeeieieaeeaieeeeaeaeeaeeieaeoeeeaiaieaieeiaieeeoooeeoeaoeaeaaeeaaeaeeeeeaeeeoeioeeaeeeeeaiiaeeeioeeoeaaeaeeoieeeaoieaeooeeeeaeooeeeeaeioeoieeioiooeeaeeaioeeeiooaeoeeaeaieooeaaeooieaeieioiaeiaeioeeeeaaeeaaeaeooeeaieaeeeaoeeieeeooeaeeaeieaoeaoeeoeaeaaeeiooeaeeiaooeoaeeaeaeeeaeeoeaeaeeeaieiaoeeaieeaeeeeiaooioeeoeieaeieeaeeeaiaieeeaeoaeeaieeeeeeoeioeeaeooeaiaeai\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ave a cry of delight and for a moment\n",
      "be\"\n",
      "ave a cry of delight and for a moment\n",
      "beeieaeiaieeaeeaeeeeioeaeeaeeaiiooeooeiiaeooeaaeeeeaaiieeeaeaoiiaeeeeaeoeeeaaeeieioeioaeoeeeeaooaeeioaeeeoieaaiooooooooeaeiaieieaeiooeaeeieioeioeaoaeeeaeeaeeaeioeaeeeeeeaeaiaeeeeeeeaeeaeiaioeaoeeaiooeooeaeaiieaeiieaaeooioioaeeieeeaiieeeaeeeaeoieeeeeaooeeaieaieeaeeeoiieeeeioeaieieeaeieaoeiooeaeooaiaeiooeaeeaieeiaaoeiaaooieeeeaeoeaoeeeeiieaoeeaeaieeieeooieeaaeeaeeeieiooeeeaieeoeeeeooeeeeaeaieeeeaeeeea\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/1\n",
      "105728/200285 [==============>...............] - ETA: 117s - loss: 11.8755"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stories for the challenge: single_supporting_fact_10k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabian/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Vocab size: 22 unique words\n",
      "Story max length: 68 words\n",
      "Query max length: 4 words\n",
      "Number of training stories: 10000\n",
      "Number of test stories: 1000\n",
      "-\n",
      "Here's what a \"story\" tuple looks like (input, query, answer):\n",
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "\n",
    "    If only_supporting is true, only the sentences\n",
    "    that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file,\n",
    "    retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([word_idx[w] for w in story])\n",
    "        queries.append([word_idx[w] for w in query])\n",
    "        answers.append(word_idx[answer])\n",
    "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
    "            pad_sequences(queries, maxlen=query_maxlen),\n",
    "            np.array(answers))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "tar = tarfile.open(path)\n",
    "\n",
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'single_supporting_fact_10k'\n",
    "challenge = challenges[challenge_type]\n",
    "\n",
    "print('Extracting stories for the challenge:', challenge_type)\n",
    "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "print('-')\n",
    "print('Vocab size:', vocab_size, 'unique words')\n",
    "print('Story max length:', story_maxlen, 'words')\n",
    "print('Query max length:', query_maxlen, 'words')\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print('-')\n",
    "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
    "print(train_stories[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Vectorizing the word sequences...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('-')\n",
    "print('Vectorizing the word sequences...')\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  5, 16, 19, 18,  9,  1,  4, 21, 19, 18, 12,  1], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "inputs: integer tensor of shape (samples, max_length)\n",
      "inputs_train shape: (10000, 68)\n",
      "inputs_test shape: (1000, 68)\n",
      "-\n",
      "queries: integer tensor of shape (samples, max_length)\n",
      "queries_train shape: (10000, 4)\n",
      "queries_test shape: (1000, 4)\n",
      "-\n",
      "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
      "answers_train shape: (10000,)\n",
      "answers_test shape: (1000,)\n",
      "-\n",
      "Compiling...\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.9416 - acc: 0.1735 - val_loss: 1.7920 - val_acc: 0.1530\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.7384 - acc: 0.2493 - val_loss: 1.5770 - val_acc: 0.3670\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.5583 - acc: 0.3696 - val_loss: 1.4858 - val_acc: 0.4240\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.5186 - acc: 0.3953 - val_loss: 1.4692 - val_acc: 0.4220\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.4762 - acc: 0.4299 - val_loss: 1.4083 - val_acc: 0.4620\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.4373 - acc: 0.4467 - val_loss: 1.3804 - val_acc: 0.4940\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.4036 - acc: 0.4618 - val_loss: 1.3452 - val_acc: 0.4750\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.3877 - acc: 0.4689 - val_loss: 1.3333 - val_acc: 0.5060\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.3595 - acc: 0.4843 - val_loss: 1.3180 - val_acc: 0.4830\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.3354 - acc: 0.4866 - val_loss: 1.3011 - val_acc: 0.4900\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.3019 - acc: 0.4998 - val_loss: 1.2434 - val_acc: 0.5160\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.2835 - acc: 0.5035 - val_loss: 1.2313 - val_acc: 0.5190\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.2521 - acc: 0.5086 - val_loss: 1.2080 - val_acc: 0.5160\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.2388 - acc: 0.5156 - val_loss: 1.1919 - val_acc: 0.5180\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.2234 - acc: 0.5114 - val_loss: 1.1786 - val_acc: 0.5120\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.2223 - acc: 0.5099 - val_loss: 1.1762 - val_acc: 0.5150\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.2144 - acc: 0.5132 - val_loss: 1.1687 - val_acc: 0.5250\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.2090 - acc: 0.5144 - val_loss: 1.1802 - val_acc: 0.5160\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1952 - acc: 0.5172 - val_loss: 1.1697 - val_acc: 0.5220\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 1.1878 - acc: 0.522 - 2s - loss: 1.1886 - acc: 0.5228 - val_loss: 1.1676 - val_acc: 0.5200\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1864 - acc: 0.5194 - val_loss: 1.1707 - val_acc: 0.5210\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 3s - loss: 1.1861 - acc: 0.5182 - val_loss: 1.1612 - val_acc: 0.5130\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1768 - acc: 0.5185 - val_loss: 1.1508 - val_acc: 0.5240\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1791 - acc: 0.5218 - val_loss: 1.1540 - val_acc: 0.5300\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1695 - acc: 0.5209 - val_loss: 1.1497 - val_acc: 0.5200\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1598 - acc: 0.5264 - val_loss: 1.1524 - val_acc: 0.5090\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1602 - acc: 0.5272 - val_loss: 1.1700 - val_acc: 0.5100\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1549 - acc: 0.5275 - val_loss: 1.1542 - val_acc: 0.5170\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1549 - acc: 0.5313 - val_loss: 1.1593 - val_acc: 0.5200\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1480 - acc: 0.5317 - val_loss: 1.1536 - val_acc: 0.5160\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1449 - acc: 0.5270 - val_loss: 1.1451 - val_acc: 0.5150\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1426 - acc: 0.5251 - val_loss: 1.1981 - val_acc: 0.4950\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.1325 - acc: 0.5339 - val_loss: 1.1539 - val_acc: 0.5240\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.1351 - acc: 0.5318 - val_loss: 1.1664 - val_acc: 0.5220\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1275 - acc: 0.5417 - val_loss: 1.1623 - val_acc: 0.5210\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1298 - acc: 0.5407 - val_loss: 1.1427 - val_acc: 0.5190\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.1219 - acc: 0.5370 - val_loss: 1.1519 - val_acc: 0.5180\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1281 - acc: 0.5332 - val_loss: 1.1470 - val_acc: 0.5240\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1120 - acc: 0.5348 - val_loss: 1.1416 - val_acc: 0.5180\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.1109 - acc: 0.5442 - val_loss: 1.1555 - val_acc: 0.5140\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.1047 - acc: 0.5412 - val_loss: 1.1472 - val_acc: 0.5270\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.1044 - acc: 0.5427 - val_loss: 1.1503 - val_acc: 0.5100\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0999 - acc: 0.5468 - val_loss: 1.1628 - val_acc: 0.5190\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 1s - loss: 1.0990 - acc: 0.5458 - val_loss: 1.1483 - val_acc: 0.5140\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0940 - acc: 0.5519 - val_loss: 1.1554 - val_acc: 0.5100\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0942 - acc: 0.5408 - val_loss: 1.1442 - val_acc: 0.5160\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0826 - acc: 0.5505 - val_loss: 1.1608 - val_acc: 0.5110\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0770 - acc: 0.5587 - val_loss: 1.1457 - val_acc: 0.5310\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0785 - acc: 0.5552 - val_loss: 1.1491 - val_acc: 0.5260\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0608 - acc: 0.5644 - val_loss: 1.1483 - val_acc: 0.5340\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0406 - acc: 0.5801 - val_loss: 1.1122 - val_acc: 0.5450\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 2s - loss: 1.0056 - acc: 0.6058 - val_loss: 1.0622 - val_acc: 0.5790\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.9401 - acc: 0.6395 - val_loss: 0.9582 - val_acc: 0.6620\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.8221 - acc: 0.6965 - val_loss: 0.7729 - val_acc: 0.7090\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.7173 - acc: 0.7446 - val_loss: 0.7111 - val_acc: 0.7390\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.6580 - acc: 0.7647 - val_loss: 0.6672 - val_acc: 0.7500\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.6176 - acc: 0.7740 - val_loss: 0.6305 - val_acc: 0.7590\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.5788 - acc: 0.7845 - val_loss: 0.6194 - val_acc: 0.7570\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.5502 - acc: 0.7955 - val_loss: 0.5982 - val_acc: 0.7640\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.5203 - acc: 0.8047 - val_loss: 0.5483 - val_acc: 0.7740\n",
      "Epoch 61/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 0.4851 - acc: 0.8168 - val_loss: 0.5289 - val_acc: 0.7990\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.4583 - acc: 0.8268 - val_loss: 0.4725 - val_acc: 0.8140\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.4363 - acc: 0.8385 - val_loss: 0.4469 - val_acc: 0.8330\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.4082 - acc: 0.8485 - val_loss: 0.4380 - val_acc: 0.8230\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.3935 - acc: 0.8535 - val_loss: 0.4354 - val_acc: 0.8370\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.3754 - acc: 0.8610 - val_loss: 0.3848 - val_acc: 0.8560\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.3622 - acc: 0.8634 - val_loss: 0.3906 - val_acc: 0.8510\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.3513 - acc: 0.8661 - val_loss: 0.3720 - val_acc: 0.8640\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.3306 - acc: 0.8774 - val_loss: 0.3823 - val_acc: 0.8610\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.3273 - acc: 0.8801 - val_loss: 0.3457 - val_acc: 0.8740\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.3108 - acc: 0.8839 - val_loss: 0.3436 - val_acc: 0.8760\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.3000 - acc: 0.8886 - val_loss: 0.3226 - val_acc: 0.8760\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2984 - acc: 0.8903 - val_loss: 0.3220 - val_acc: 0.8810\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.2842 - acc: 0.8942 - val_loss: 0.3226 - val_acc: 0.8880\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.2657 - acc: 0.9005 - val_loss: 0.3418 - val_acc: 0.8840\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2621 - acc: 0.9039 - val_loss: 0.2954 - val_acc: 0.8880\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2510 - acc: 0.9060 - val_loss: 0.2726 - val_acc: 0.8970\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.2457 - acc: 0.9096 - val_loss: 0.2538 - val_acc: 0.9030\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.2364 - acc: 0.9171 - val_loss: 0.2734 - val_acc: 0.9010\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2216 - acc: 0.9212 - val_loss: 0.2460 - val_acc: 0.9070\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2193 - acc: 0.9215 - val_loss: 0.2254 - val_acc: 0.9170\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2072 - acc: 0.9267 - val_loss: 0.2570 - val_acc: 0.9060\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2108 - acc: 0.9251 - val_loss: 0.2380 - val_acc: 0.9080\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.2031 - acc: 0.9267 - val_loss: 0.2152 - val_acc: 0.9190\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1834 - acc: 0.9365 - val_loss: 0.2084 - val_acc: 0.9260\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1867 - acc: 0.9311 - val_loss: 0.1946 - val_acc: 0.9260\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1759 - acc: 0.9375 - val_loss: 0.1914 - val_acc: 0.9350\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1721 - acc: 0.9390 - val_loss: 0.1871 - val_acc: 0.9270\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1679 - acc: 0.9406 - val_loss: 0.1849 - val_acc: 0.9230\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1615 - acc: 0.9444 - val_loss: 0.1906 - val_acc: 0.9290\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1652 - acc: 0.9412 - val_loss: 0.2025 - val_acc: 0.9240\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1535 - acc: 0.9463 - val_loss: 0.1739 - val_acc: 0.9350\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1576 - acc: 0.9461 - val_loss: 0.1908 - val_acc: 0.9330\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1462 - acc: 0.9484 - val_loss: 0.1763 - val_acc: 0.9350\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1399 - acc: 0.9518 - val_loss: 0.1753 - val_acc: 0.9360\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1394 - acc: 0.9488 - val_loss: 0.1669 - val_acc: 0.9380\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1347 - acc: 0.9523 - val_loss: 0.1743 - val_acc: 0.9400\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1265 - acc: 0.9558 - val_loss: 0.1931 - val_acc: 0.9340\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1284 - acc: 0.9554 - val_loss: 0.1567 - val_acc: 0.9460\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1281 - acc: 0.9548 - val_loss: 0.1738 - val_acc: 0.9380\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1163 - acc: 0.9580 - val_loss: 0.1862 - val_acc: 0.9370\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1172 - acc: 0.9592 - val_loss: 0.1516 - val_acc: 0.9460\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1160 - acc: 0.9596 - val_loss: 0.1421 - val_acc: 0.9490\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.1129 - acc: 0.9594 - val_loss: 0.1718 - val_acc: 0.9390\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1129 - acc: 0.9608 - val_loss: 0.1633 - val_acc: 0.9420\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1084 - acc: 0.9621 - val_loss: 0.1442 - val_acc: 0.9540\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.1034 - acc: 0.9644 - val_loss: 0.1511 - val_acc: 0.9520\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0980 - acc: 0.9655 - val_loss: 0.1653 - val_acc: 0.9530\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0952 - acc: 0.9682 - val_loss: 0.1545 - val_acc: 0.9410\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.0959 - acc: 0.9663 - val_loss: 0.1648 - val_acc: 0.9460\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.0938 - acc: 0.9675 - val_loss: 0.1583 - val_acc: 0.9580\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0931 - acc: 0.9673 - val_loss: 0.1431 - val_acc: 0.9500\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0916 - acc: 0.9688 - val_loss: 0.1629 - val_acc: 0.9390\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.0929 - acc: 0.9681 - val_loss: 0.1310 - val_acc: 0.9560\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.0839 - acc: 0.9707 - val_loss: 0.1404 - val_acc: 0.9470\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0877 - acc: 0.9715 - val_loss: 0.1540 - val_acc: 0.9520\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0829 - acc: 0.9713 - val_loss: 0.1459 - val_acc: 0.9530\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 1s - loss: 0.0901 - acc: 0.9716 - val_loss: 0.1268 - val_acc: 0.9580\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0836 - acc: 0.9723 - val_loss: 0.1590 - val_acc: 0.9520\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 2s - loss: 0.0797 - acc: 0.9720 - val_loss: 0.1797 - val_acc: 0.9480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff689a53518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('-')\n",
    "print('inputs: integer tensor of shape (samples, max_length)')\n",
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)\n",
    "print('-')\n",
    "print('queries: integer tensor of shape (samples, max_length)')\n",
    "print('queries_train shape:', queries_train.shape)\n",
    "print('queries_test shape:', queries_test.shape)\n",
    "print('-')\n",
    "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
    "print('answers_train shape:', answers_train.shape)\n",
    "print('answers_test shape:', answers_test.shape)\n",
    "print('-')\n",
    "print('Compiling...')\n",
    "\n",
    "# placeholders\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "# encoders\n",
    "# embed the input sequence into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=query_maxlen))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=query_maxlen))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "# the original paper uses a matrix multiplication for this reduction step.\n",
    "# we choose to use a RNN instead.\n",
    "answer = LSTM(32)(answer)  # (samples, 32)\n",
    "\n",
    "# one regularization layer -- more would probably be needed.\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=120,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ef41745d1c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minitial_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
